{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO38IqWFCA0NEaIh9kYwrAq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# AlexNet 로드"],"metadata":{"id":"BNv5T8JSCbTE"}},{"cell_type":"markdown","source":["알렉스넷 모델 구조 출력"],"metadata":{"id":"DLirLd7Z__Dv"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cc7d4mMF_jbp","executionInfo":{"status":"ok","timestamp":1760601161484,"user_tz":-540,"elapsed":4192,"user":{"displayName":"최원진","userId":"05911164394888239170"}},"outputId":"5028d38b-3ce9-41fb-8c8b-ad3f7373e7eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233M/233M [00:02<00:00, 91.8MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","AlexNet                                  [1, 1000]                 --\n","├─Sequential: 1-1                        [1, 256, 6, 6]            --\n","│    └─Conv2d: 2-1                       [1, 64, 55, 55]           23,296\n","│    └─ReLU: 2-2                         [1, 64, 55, 55]           --\n","│    └─MaxPool2d: 2-3                    [1, 64, 27, 27]           --\n","│    └─Conv2d: 2-4                       [1, 192, 27, 27]          307,392\n","│    └─ReLU: 2-5                         [1, 192, 27, 27]          --\n","│    └─MaxPool2d: 2-6                    [1, 192, 13, 13]          --\n","│    └─Conv2d: 2-7                       [1, 384, 13, 13]          663,936\n","│    └─ReLU: 2-8                         [1, 384, 13, 13]          --\n","│    └─Conv2d: 2-9                       [1, 256, 13, 13]          884,992\n","│    └─ReLU: 2-10                        [1, 256, 13, 13]          --\n","│    └─Conv2d: 2-11                      [1, 256, 13, 13]          590,080\n","│    └─ReLU: 2-12                        [1, 256, 13, 13]          --\n","│    └─MaxPool2d: 2-13                   [1, 256, 6, 6]            --\n","├─AdaptiveAvgPool2d: 1-2                 [1, 256, 6, 6]            --\n","├─Sequential: 1-3                        [1, 1000]                 --\n","│    └─Dropout: 2-14                     [1, 9216]                 --\n","│    └─Linear: 2-15                      [1, 4096]                 37,752,832\n","│    └─ReLU: 2-16                        [1, 4096]                 --\n","│    └─Dropout: 2-17                     [1, 4096]                 --\n","│    └─Linear: 2-18                      [1, 4096]                 16,781,312\n","│    └─ReLU: 2-19                        [1, 4096]                 --\n","│    └─Linear: 2-20                      [1, 1000]                 4,097,000\n","==========================================================================================\n","Total params: 61,100,840\n","Trainable params: 61,100,840\n","Non-trainable params: 0\n","Total mult-adds (Units.MEGABYTES): 714.68\n","==========================================================================================\n","Input size (MB): 0.60\n","Forward/backward pass size (MB): 3.95\n","Params size (MB): 244.40\n","Estimated Total Size (MB): 248.96\n","=========================================================================================="]},"metadata":{},"execution_count":3}],"source":["from torchvision import models\n","from torchinfo import summary\n","\n","model = models.alexnet(weights=\"AlexNet_Weights.IMAGENET1K_V1\")\n","summary(model, (1, 3, 224, 224), device=\"cpu\")"]},{"cell_type":"markdown","source":["클래스 정보 파일 불러오기"],"metadata":{"id":"UT331QQ0ADp7"}},{"cell_type":"code","source":["with open(\"/content/imagenet_classes.txt\", \"r\") as file:\n","    classes = file.read().splitlines()\n","\n","print(f\"클래스 개수 : {len(classes)}\")\n","print(f\"첫 번째 클래스 레이블 : {classes[0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bAcRvRkqAIAk","executionInfo":{"status":"ok","timestamp":1760601167286,"user_tz":-540,"elapsed":11,"user":{"displayName":"최원진","userId":"05911164394888239170"}},"outputId":"770945e3-8a58-48f8-f285-1d388355c352"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["클래스 개수 : 1000\n","첫 번째 클래스 레이블 : tench\n"]}]},{"cell_type":"markdown","source":["# 전처리"],"metadata":{"id":"v0AmSUmsCgIJ"}},{"cell_type":"markdown","source":["알렉스넷은 입력 이미지로 256 x 256 크기를 사용하며, RGB 픽셀값의 평균과 분산을 활용해 정규화를 적용한다.  \n","<br>\n","아래 코드는 통합 클래스를 활용해 알렉스넷이 학습한 데이터와 동일한 형태로 전처리하는 방법이다."],"metadata":{"id":"8njIMsfRAdTs"}},{"cell_type":"code","source":["import torch\n","from PIL import Image\n","from torchvision import models, transforms\n","\n","\n","transform = transforms.Compose(\n","    [\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(\n","            mean=[0.485, 0.456, 0.406],\n","            std=[0.229, 0.224, 0.225]\n","        ),\n","    ]\n",")\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model = models.alexnet(weights=\"AlexNet_Weights.IMAGENET1K_V1\").eval().to(device)\n","\n","tensors = []\n","files = [\"/content/airplane.jpg\", \"/content/bus.jpg\"]\n","for file in files:\n","    image = Image.open(file)\n","    tensors.append(transform(image))\n","\n","tensors = torch.stack(tensors)\n","print(f\"입력 텐서의 크기 : {tensors.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xmT6sn9BA7lJ","executionInfo":{"status":"ok","timestamp":1760601381442,"user_tz":-540,"elapsed":1278,"user":{"displayName":"최원진","userId":"05911164394888239170"}},"outputId":"2bf4e6fc-6e8a-43b5-e38a-afc5d93a46f0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["입력 텐서의 크기 : torch.Size([2, 3, 224, 224])\n"]}]},{"cell_type":"markdown","source":["위의 정규화 클래스(Normalize)의 평균과 표준편차 값은 이미지넷 데이터세트에서 사용된 이미지들의 평균과 표준편차 값이다.  \n","<br>\n","이미지넷 데이터는 CV 분야에서 일반적으로 사용되는 대규모 시각 인식 데이터세트이다.  \n","1,400만 개 이상의 이미지가 포함돼 있으므로 자연물이나 일상생활과 관련된 데이터일 경우 해당 평균과 표준편차를 사용할 때 가장 우수한 정규화 값으로 수행된다."],"metadata":{"id":"pLdo4jDtBRRN"}},{"cell_type":"markdown","source":["# 모델 학습"],"metadata":{"id":"gH5fiAevCHmw"}},{"cell_type":"code","source":["import numpy as np\n","from torch.nn import functional as F\n","\n","\n","with torch.no_grad():\n","    outputs = model(tensors.to(device))\n","    probs = F.softmax(outputs, dim=-1)\n","    top_probs, top_idxs = probs.topk(5)\n","\n","top_probs = top_probs.detach().cpu().numpy()\n","top_idxs = top_idxs.detach().cpu().numpy()\n","top_classes = np.array(classes)[top_idxs]\n","\n","for idx, (cls, prob) in enumerate(zip(top_classes, top_probs)):\n","    print(f\"{files[idx]} 추론 결과\")\n","    for c, p in zip(cls, prob):\n","        print(f\" - {c:<30} : {p * 100:>5.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LPfnabxSCl2j","executionInfo":{"status":"ok","timestamp":1760601750660,"user_tz":-540,"elapsed":1078,"user":{"displayName":"최원진","userId":"05911164394888239170"}},"outputId":"12fdc91c-f2ac-4d2f-9875-7e08a96d07fe"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/airplane.jpg 추론 결과\n"," - airliner                       : 66.83%\n"," - warplane                       : 20.12%\n"," - wing                           :  9.29%\n"," - space shuttle                  :  2.89%\n"," - missile                        :  0.38%\n","/content/bus.jpg 추론 결과\n"," - streetcar                      : 60.25%\n"," - trolleybus                     : 37.99%\n"," - minibus                        :  1.54%\n"," - passenger car                  :  0.17%\n"," - recreational vehicle           :  0.03%\n"]}]},{"cell_type":"markdown","source":["임의의 값으로 모델을 확인하므로 torch.no_grad 클래스로 기울기 계산 비활성화."],"metadata":{"id":"xhVpatUpCreK"}},{"cell_type":"code","source":[],"metadata":{"id":"PaPUk-7_DK9R"},"execution_count":null,"outputs":[]}]}